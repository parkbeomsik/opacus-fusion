
/*
    Generated by generate_cutlass_code.py - Do not edit.
*/

#include "cutlass/cutlass.h"
#include "cutlass/gemm/gemm.h"
#include "cutlass/conv/convolution.h"
#include "cutlass/conv/conv2d_problem_size.h"
#include "cutlass/conv/kernel/implicit_gemm_convolution_grouped.h"
#include "cutlass/conv/kernel/default_conv2d_wgrad.h"
#include "cutlass/conv/kernel/default_conv2d_wgrad_grouped.h"
#include "cutlass/conv/device/implicit_gemm_convolution_grouped.h"
#include "cutlass/conv/device/implicit_gemm_convolution.h"

////////////////////////////////////////////////////////////////////

int main() {

  using cutlass_simt_iwgrad_grouped_optimized_256x256x32_128x128x32_1x1x4_3_nhwc = typename cutlass::conv::kernel::DefaultConv2dWgradGrouped<
      int8_t, 
      cutlass::layout::TensorNHWC,
      int8_t,
      cutlass::layout::TensorNHWC,
      float, cutlass::layout::TensorNHWC,
      int32_t, 
      cutlass::arch::OpClassSimt, 
      cutlass::arch::Sm80,
      cutlass::gemm::GemmShape<256, 256, 32>,
      cutlass::gemm::GemmShape<128, 128, 32>,
      cutlass::gemm::GemmShape<1, 1, 4>,
      cutlass::epilogue::thread::LinearCombination<
          float, 1,
          int32_t, float>,
      cutlass::gemm::threadblock::GemmBatchedIdentityThreadblockSwizzle, 
      3,
      cutlass::arch::OpMultiplyAdd,
      cutlass::conv::IteratorAlgorithm::kOptimized
      >::Conv2dWgradKernel;

  using test = cutlass::conv::device::ImplicitGemmConvolutionGrouped<
      cutlass_simt_iwgrad_grouped_optimized_256x256x32_128x128x32_1x1x4_3_nhwc>;

  return 0;

}

///////////////////////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////////////////////
    