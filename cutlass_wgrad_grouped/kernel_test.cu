
/*
    Generated by generate_cutlass_code.py - Do not edit.
*/

#include "cutlass/cutlass.h"
#include "cutlass/gemm/gemm.h"
#include "cutlass/conv/convolution.h"
#include "cutlass/conv/conv2d_problem_size.h"
#include "cutlass/conv/kernel/implicit_gemm_convolution_grouped.h"
#include "cutlass/conv/kernel/default_conv2d_wgrad.h"
#include "cutlass/conv/kernel/default_conv2d_wgrad_grouped.h"
#include "cutlass/conv/device/implicit_gemm_convolution_grouped.h"
#include "cutlass/conv/device/implicit_gemm_convolution.h"

////////////////////////////////////////////////////////////////////

int main() {

  using cutlass_tensorop_iwgrad_grouped_optimized_32x64x32_32x64x32_8x8x16_3_nhwc = typename cutlass::conv::kernel::DefaultConv2dWgradGrouped<
      int8_t, 
      cutlass::layout::TensorNHWC,
      int8_t,
      cutlass::layout::TensorNHWC,
      float, cutlass::layout::TensorNHWC,
      int32_t, 
      cutlass::arch::OpClassTensorOp, 
      cutlass::arch::Sm80,
      cutlass::gemm::GemmShape<32, 64, 32>,
      cutlass::gemm::GemmShape<32, 64, 32>,
      cutlass::gemm::GemmShape<8, 8, 16>,
      cutlass::epilogue::thread::LinearCombination<
          float, 128 / cutlass::sizeof_bits<int32_t>::value,
          int32_t, float>,
      cutlass::gemm::threadblock::GemmBatchedIdentityThreadblockSwizzle, 
      3,
      cutlass::arch::OpMultiplyAdd,
      cutlass::conv::IteratorAlgorithm::kOptimized
      >::Conv2dWgradKernel;

  using test = cutlass::conv::device::ImplicitGemmConvolutionGrouped<
      cutlass_tensorop_iwgrad_grouped_optimized_32x64x32_32x64x32_8x8x16_3_nhwc>;

  return 0;

}

///////////////////////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////////////////////
    